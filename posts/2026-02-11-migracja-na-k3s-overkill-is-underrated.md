---
id: '16'
title: 'Migracja na K3s: Zamieni≈Çem prostego Dockera w DevOpsowƒÖ Gwiazdƒô ≈ömierci'
date: '2026-02-11'
tags: ['K3s', 'Kubernetes', 'Terraform', 'Ansible', 'CI/CD', 'Homelab']
readTime: '5 min'
imageUrl: '/k3s-migration-v2-1770824382.png'
excerpt: 'Od Terraformowania LXC, przez Ansible, a≈º po hybrydowe CI/CD z lokalnym rejestrem. Pe≈Çny zapis walki o idealnƒÖ infrastrukturƒô.'
---

Dzisiaj wjecha≈Ç temat, kt√≥ry od dawna wisia≈Ç na mojej **ROADMAPIE DO CKA**: Migracja bloga na klaster Kubernetes (K3s). Ale nie byle jaka. Zrobi≈Çem to w stylu "Overkill is Underrated".

Zamiast po prostu wrzuciƒá to na klaster, zbudowa≈Çem **"Ku≈∫niƒô" (The Forge)** ‚Äì dedykowany, lokalny system CI/CD, kt√≥ry mieli buildy szybciej, ni≈º zdƒÖ≈ºysz powiedzieƒá "kubectl apply".

Oto jak to wyglƒÖda pod maskƒÖ.

## 1. Architektura: The Forge ("Ku≈∫nia")

M√≥j klaster K3s potrzebowa≈Ç wsparcia. Potrzebowa≈Çem miejsca, gdzie:
1. BudujƒÖ siƒô obrazy (bez zapychania CPU na masterze).
2. Obrazy sƒÖ trzymane lokalnie (po co pchaƒá GB danych do GHCR, skoro serwer stoi metr dalej?).

RozwiƒÖzanie? **LXC Container na Proxmoxie**, postawiony oczywi≈õcie jako IaC.

### Terraform: Powstanie Ku≈∫ni
Nie klikamy w GUI Proxmoxa. Definiujemy stan. Oto fragment mojego `kuznia.tf`:

```hcl
resource "proxmox_virtual_environment_container" "kuznia" {
  node_name = "proxmox-worker" 
  vm_id     = 200

  initialization {
    hostname = "kuznia"
    ip_config {
      ipv4 {
        address = "10.0.20.50/24" # VLAN 20 - szybka ≈õcie≈ºka do K3s
        gateway = "10.0.20.1"
      }
    }
  }

  # KLUCZOWE: Nesting w≈ÇƒÖczony, ≈ºeby Docker dzia≈Ça≈Ç w LXC
  features {
    nesting = true
  }
  
  unprivileged = true # Security first!
}
```

## 2. Ansible: Konfiguracja "Bez Dotykania"

Jak ju≈º Terraform wyplu≈Ç kontener, wjecha≈Ç Ansible. Zadania?
1. Zainstalowaƒá Dockera.
2. Postawiƒá lokalny rejestr obraz√≥w (`registry:2` na porcie 5000).
3. Zarejestrowaƒá **GitHub Self-Hosted Runnera**.

Najwiƒôkszy flex? **Automatyczna rejestracja runnera**. Ansible sam gada z API GitHuba, pobiera token rejestracyjny i wpina maszynƒô do repo. Zero wklejania token√≥w do terminala.

Fragment `setup_kuznia.yml`:

```yaml
    - name: Skonfiguruj i zarejestruj runnera (Unattended)
      command: >
        ./config.sh --url https://github.com/kompot-rar/Vibe_devops
        --token {{ registration_response.json.token }}
        --name "Kuznia-LXC"
        --labels "k3s-dev"
        --unattended
```

## 3. Pipeline: Hybrydowe CI/CD (Lokalnie + Chmura)

Pipeline dzia≈Ça tak:
1. **GitHub** widzi pusha.
2. **Ku≈∫nia** (m√≥j lokalny runner) wstaje.
3. **Build:** Docker buduje obraz na dysku NVMe (cache dzia≈Ça b≈Çyskawicznie).
4. **Push:** 
    *   G≈Ç√≥wny strza≈Ç leci do `localhost:5000` (Lokalny Rejestr). Transfer? Gigabit LAN. Czas? Sekundy.
    *   Backup leci do GHCR (Cloud), ≈ºeby mieƒá kopiƒô zapasowƒÖ.

M√≥j `.github/workflows/deploy.yml` po tuningu:

```yaml
  build-k8s:
    runs-on: k3s-dev # Celujemy w Ku≈∫niƒô po etykiecie
    steps:
      - name: Build & Push (Local & GHCR)
        env:
          GHCR_IMAGE: ghcr.io/${{ github.repository_owner }}/vibe-devops:dev
          LOCAL_IMAGE: localhost:5000/vibe-devops:dev
        run: |
          echo "Building image on The Forge..."
          docker build -t $GHCR_IMAGE -t $LOCAL_IMAGE .
          
          echo "Pushing to local registry (Speed: üöÄ)..."
          docker push $LOCAL_IMAGE
          
          echo "Pushing to GHCR (Backup)..."
          docker push $GHCR_IMAGE
```

## 4. Kubernetes & GitOps: Fina≈Ç

Na ko≈Ñcu K3s pobiera obraz z lokalnego rejestru (`10.0.20.50:5000`). Musia≈Çem przekonaƒá K3s, ≈ºeby ufa≈Ç rejestrowi HTTP (insecure), ale Ansiblem podmieni≈Çem `registries.yaml` na wszystkich nodach w 3 sekundy.

Aplikacja jest wystawiona na ≈õwiat przez **Cloudflare Tunnel**. Zero otwartych port√≥w na routerze, pe≈Çny SSL, zero stresu.

Manifest `deployment.yaml` (czysta poezja):

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blog-dev
  namespace: dev
spec:
  replicas: 2 # High Availability w domu? Czemu nie.
  template:
    spec:
      containers:
      - name: blog
        image: 10.0.20.50:5000/vibe-devops:dev # <--- Tu jest magia!
        imagePullPolicy: Always
```

## Fina≈Ç!

Ostateczny test przyszed≈Ç 10 lutego, kiedy branch `main` oficjalnie wjecha≈Ç na klaster. Po drodze musia≈Çem jeszcze powalczyƒá z KUBECONFIG-iem dla zewnƒôtrznego runnera (wskazanie na VIP klastra 10.0.20.10 by≈Ço kluczowe) i od≈õwie≈ºyƒá tunel Cloudflare, ale efekt ko≈Ñcowy jest wart ka≈ºdej minuty debugowania. Blog pod adresem [devops.mrozy.org](https://devops.mrozy.org) dzia≈Ça teraz jako pe≈Çnoprawna us≈Çuga klastrowa, a ka≈ºde `git push` wyzwala lokalny build w "Ku≈∫ni" i automatyczny deployment przez ArgoCD.

To nie jest ju≈º tylko labowa zabawa ‚Äì to produkcyjna architektura, gdzie GitOps pilnuje stanu aplikacji, a Cloudflare Tunnel dba o to, by ≈õwiat widzia≈Ç moje postƒôpy bez wystawiania infrastruktury na strza≈Ç. Zamiast prostych kontener√≥w, mam teraz skalowalny ekosystem, kt√≥ry jest gotowy na kolejne modu≈Çy. Nastƒôpny przystanek? Pe≈Çny stos Observability, bo to, co dzia≈Ça na produkcji, musi byƒá przede wszystkim widoczne. 

---
*Repozytorium projektu: [GitHub](https://github.com/kompot-rar/Vibe_devops)*
